# Project Title :
Machine Learning-Predictive-Eye-Tracking-Integration-Project.

## Project Overview :
This machine learning project for predictive eye tracking is an ambitious endeavor driven by the overarching goal of elevating the precision and depth of consumer behavior analysis. 
By leveraging the power of predictive eye tracking, the platform aims to unravel nuanced insights into visual attention, 
emotional responses, and decision-making processes, ultimately reshaping how businesses understand and influence their target audience.

## Project Highlights :
### Motivation:
Enhanced User Experience: Smoother and more responsive interactions through advanced gaze prediction.
Adaptive User Interfaces: Personalized experiences by integrating predictive eye tracking with UI.
Attention-Based Analytics: Insights into users' visual attention patterns for improved decision-making.

### Data Collection and Preprocessing:
Collecting eye tracking and facial coding data for explicit and implicit feedback during surveys.
Preprocessing involves handling missing data, interpolating values, and scaling features for analysis.

### Feature Importance and Selection:
Identification of relevant features using techniques like tree-based models, permutation importance, and drop columns importance.
Application of feature importance for model understanding, selection, and engineering.

### Modeling and Experiments:
Training baseline Linear Regression (LR) model and experimenting with top features from RFE, permutation importance, and drop columns importance.
Utilizing PCA for dimensionality reduction and assessing model scores.

### Hyperparameter Tuning and Evaluation:
Tuning models with techniques such as Grid Search CV, Random Search, Bayesian Optimization, and Genetic Algorithm.
Evaluation metrics include MAE, MSE, and R2, ensuring robustness and generalizability.

### Machine Learning Models:
Experimenting with Decision Trees, Random Forests, K-nearest neighbors (KNN), and Neural Networks.
Concluding that Neural Networks outperform other models, especially in capturing temporal dependencies.

### Sequence-to-Sequence Models:
Implementing Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) Networks.
Employing sequence-to-sequence models with transfer learning for enhanced prediction.


  ## Team Memebers:
- Ivana Gerchakova
- Margareta Goseva
- Stevo Dimovski
- Ivana Atanasovska
  
## Project Preview :
<img src="Images/Do not reject H0.png">
